{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from os import path\n",
    "import wave\n",
    "import contextlib\n",
    "import webrtcvad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Writes a .wav file.\n",
    "\n",
    "Takes the path, and frames and writes the frame data to the path file.\n",
    "\"\"\"\n",
    "def write_wave(path, frames, sample_rate):\n",
    "    wav_file=wave.open(path,\"w\")\n",
    "    nchannels = 1\n",
    "    sampwidth = 2\n",
    "    nframes = len(frames)\n",
    "    comptype = \"NONE\"\n",
    "    compname = \"not compressed\"\n",
    "    wav_file.setparams((nchannels, sampwidth, sample_rate, nframes, comptype, compname))\n",
    "    wav_file.writeframes(b''.join(frames))\n",
    "    wav_file.close()\n",
    "    #print('Created chunk file at: '+path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Reads a .wav file.\n",
    "\n",
    "Takes the path, and returns (PCM audio data, sample rate).\n",
    "\"\"\"\n",
    "def read_wave(path):\n",
    "    with contextlib.closing(wave.open(path, 'rb')) as wf:\n",
    "        num_channels = wf.getnchannels()\n",
    "        assert num_channels == 1\n",
    "        sample_width = wf.getsampwidth()\n",
    "        assert sample_width == 2\n",
    "        sample_rate = wf.getframerate()\n",
    "        assert sample_rate in (8000, 16000, 32000)\n",
    "        frames = wf.getnframes()\n",
    "        pcm_data = wf.readframes(frames)\n",
    "        duration = frames / sample_rate\n",
    "        return pcm_data, sample_rate, duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Frame(object):\n",
    "    \"\"\"Represents a \"frame\" of audio data.\"\"\"\n",
    "    def __init__(self, bytes, timestamp, duration):\n",
    "        self.bytes = bytes\n",
    "        self.timestamp = timestamp\n",
    "        self.duration = duration\n",
    "class Snippet(object):\n",
    "    \"\"\"Represents a snippet of the audio file post performing vad.\"\"\"\n",
    "    def __init__(self, path, from_time, to_time):\n",
    "        self.path = path\n",
    "        self.from_time = from_time\n",
    "        self.to_time = to_time\n",
    "        self.responses = []\n",
    "        self.signals = []\n",
    "    def add_signal(self , signal):\n",
    "        self.signals.append(signal)\n",
    "    def add_transcription(self, responses):\n",
    "        self.responses = responses\n",
    "    def set_speaker(self, speaker):\n",
    "        self.speaker = speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_vad_sil(file_path, chunk_folder_path, frame_duration_ms = 30, min_silence = 0.06,min_voice = 3):\n",
    "    snippets = []\n",
    "    print('Processing '+ file_path+' for voice activity detection...')\n",
    "    if os.path.isdir(chunk_folder_path) is False:\n",
    "        print('Creating chunk folder at: '+chunk_folder_path)\n",
    "        os.makedirs(chunk_folder_path)\n",
    "    aggressiveness = 2\n",
    "    directory = os.fsencode(chunk_folder_path)\n",
    "    fileName = os.path.basename(file_path).replace('.wav','')\n",
    "    vad = webrtcvad.Vad(aggressiveness)\n",
    "    chunk_count = 0\n",
    "    accumulated_frames = []\n",
    "    audio, sample_rate, audio_length = read_wave(file_path)\n",
    "    assert sample_rate in (8000, 16000, 32000)\n",
    "    n = int(sample_rate * (frame_duration_ms / 1000.0) * 2)\n",
    "    offset = 0\n",
    "    timestamp = 0.0\n",
    "    chunk_from = 0.0\n",
    "    chunk_to = 0.0\n",
    "    duration = (float(n) / sample_rate) / 2.0\n",
    "    acc_sil = 0.0\n",
    "    is_sil = False\n",
    "    err_counter = 0\n",
    "    accu_sil = 0.0\n",
    "    while offset + n < len(audio):\n",
    "        frame = Frame(audio[offset:offset + n], timestamp, duration)\n",
    "        is_speech = vad.is_speech(frame.bytes, sample_rate)\n",
    "        print(str(chunk_from)+'->'+str(chunk_to)+'->'+str(is_speech)+'->'+str(acc_sil))\n",
    "        accumulated_frames.append(audio[offset:offset + n])\n",
    "        if(chunk_from == chunk_to):\n",
    "            chunk_from = offset/len(audio)*audio_length\n",
    "        chunk_to = (offset+n)/len(audio)*audio_length\n",
    "        print(str(is_speech)+str(acc_sil))\n",
    "        if not is_speech:\n",
    "            accu_sil += frame_duration_ms\n",
    "            if accu_sil>0.29:\n",
    "                if len(accumulated_frames)>100:\n",
    "                    chunk_file_path = chunk_folder_path+fileName+\"_{:03}\".format(chunk_count)+'.wav'\n",
    "                    write_wave(chunk_file_path,accumulated_frames,sample_rate)\n",
    "                    snippets.append(Snippet(chunk_file_path, chunk_from, chunk_to))\n",
    "                    print('Creating chunk from: '+ str(chunk_from)  +'to: '+ str(chunk_to) +': '+ chunk_file_path)\n",
    "                    chunk_count = chunk_count + 1\n",
    "                accumulated_frames = []\n",
    "                chunk_from = chunk_to\n",
    "        else:\n",
    "            accu_sil = 0.0\n",
    "        timestamp += duration\n",
    "        offset += n\n",
    "    print('eErrors: '+str(err_counter))\n",
    "    return snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_lines(file_path):\n",
    "    file = open(file_path,\"r\") \n",
    "    lines = file.readlines()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_srt(srt_path, delta, chunk_path):\n",
    "    lines = read_file_lines(srt_path)\n",
    "    for line in lines:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "        \n",
    "def read_subs(sub_path):\n",
    "    with open(...) as f:\n",
    "    for line in f:\n",
    "        if len(line.strip())>0:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3env",
   "language": "python",
   "name": "py3env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
