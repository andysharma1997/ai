{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch all the analysis objects\n",
    "import psycopg2\n",
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to database in 0.001 seconds\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    conn = psycopg2.connect(\"dbname='sales' user='postgres' host='db.talentify.in' password='cx6ac54nmgGtLD1y'\")\n",
    "    print(\"Connected to database in {:.03f} seconds\".format((time.time()- start)/1000))\n",
    "except:\n",
    "    print(\"I am unable to connect to the database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing select analytics from task where status = 'COMPLETED' and length(analytics)>5000 order by id desc\n",
      "Fetched 48607 results in 0.113 seconds\n"
     ]
    }
   ],
   "source": [
    "sql = \"select analytics from task where status = 'COMPLETED' and length(analytics)>1000 order by id desc\"\n",
    "cur = conn.cursor()\n",
    "print('Executing {}'.format(sql))\n",
    "cur.execute(sql)\n",
    "rows = cur.fetchall()\n",
    "\n",
    "print(\"Fetched {} results in {:.03f} seconds\".format(len(rows), (time.time()- start)/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Snippet:\n",
    "    def __init__(self, transcription, signal):\n",
    "        self.transcription = transcription\n",
    "        self.signal = signal\n",
    "        \n",
    "    def print(self):\n",
    "        print(\"{} --> {}\".format(self.transcription ,self.signal))\n",
    "        \n",
    "    def print_clean(self):\n",
    "        print(\"{} --> {}\".format(self.clean_text ,self.signal))\n",
    "        \n",
    "    def set_clean_text(self, clean_text):\n",
    "        self.clean_text = clean_text\n",
    "    \n",
    "    def set_idx_arr(self, idx_arr):\n",
    "        self.idx_arr = idx_arr\n",
    "    \n",
    "    def set_word_arr(self, word_arr):\n",
    "        self.word_arr = word_arr\n",
    "        \n",
    "snips = [] \n",
    "import json\n",
    "for row in rows:\n",
    "    ser_ana = row[0]\n",
    "    ana = json.loads(ser_ana)\n",
    "    convs = ana['conversation']\n",
    "    for conv in convs:\n",
    "        if 'text' in conv:\n",
    "            if len(conv['text'])>10:\n",
    "                is_greeting = False\n",
    "                texts.append([conv['text']])\n",
    "                for signal in conv['signals']:\n",
    "                    #print('\\t'+signal['name'])\n",
    "                    if 'greet' in signal['name'].lower():\n",
    "                        is_greeting = True\n",
    "                        break\n",
    "                snips.append(Snippet(conv['text'], is_greeting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split snips into greeting/ non-greeting -> snip_greet (~5000), snip_no_greet (500000)\n",
    "# Create new list with all snip_greet and equal number from snip_no_great -> strips_new (~10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for snip in snips:\n",
    "    #snip.set_clean_text(re.sub(\"[_,.':@#?!&$\\\"-]\", '', snip.transcription).strip().lower())\n",
    "    snip.set_clean_text(snip.transcription.strip().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "for snip in snips:\n",
    "    for word in snip.clean_text.split(' '):\n",
    "        if word not in word_list:\n",
    "            word_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_array_to_word_index_array(word_array, word_list):\n",
    "    word_index_array = []\n",
    "    for word in word_array:\n",
    "        word_index_array.append(word_list.index(word))\n",
    "    return word_index_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_word_array(sentence):\n",
    "    return sentence.split(\" \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "for snip in snips:\n",
    "    word_arr = sentence_to_word_array(snip.clean_text) #['hi', 'my', 'name', 'is', 'chirag']\n",
    "    idx_arr = word_array_to_word_index_array(word_arr, word_list) # [143, 12, 1, 768, 2121]\n",
    "    snip.set_idx_arr(idx_arr)\n",
    "    snip.set_word_arr(word_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = []\n",
    "labels = []\n",
    "for snip in snips:\n",
    "    data.append(snip.idx_arr)\n",
    "    if snip.signal==True:\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "test_labels = []\n",
    "train_data = []\n",
    "train_labels = []\n",
    "# Split\n",
    "import random\n",
    "for snip in snips:\n",
    "    ran = random.random() * 100\n",
    "    if ran < 50:\n",
    "        train_data.append(snip.idx_arr)\n",
    "        if snip.signal==True:\n",
    "            train_labels.append(1)\n",
    "        else:\n",
    "            train_labels.append(0)\n",
    "    else:\n",
    "        test_data.append(snip.idx_arr)\n",
    "        if snip.signal==True:\n",
    "            test_labels.append(1)\n",
    "        else:\n",
    "            test_labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = np.array(data)\n",
    "labels  = np.array(labels)\n",
    "test_data  = np.array(test_data)\n",
    "test_labels  = np.array(test_labels)\n",
    "train_data  = np.array(train_data)\n",
    "train_labels  = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_list_to_word_index(word_list):\n",
    "    word_index = {}\n",
    "    for word, index in enumerate(word_list):\n",
    "        word_index[index] = word\n",
    "    return word_index\n",
    "\n",
    "word_index= word_list_to_word_index(word_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first indices are reserved\n",
    "word_index = {k:(v+3) for k,v in word_index.items()} \n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  # unknown\n",
    "word_index[\"<UNUSED>\"] = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
    "\n",
    "def encode_review(text, word_list):\n",
    "    word_arr = sentence_to_word_array(text) #['hi', 'my', 'name', 'is', 'chirag']\n",
    "    idx_arr = word_array_to_word_index_array(word_arr, word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
    "                                                        value=word_index[\"<PAD>\"],\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=256)\n",
    "\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
    "                                                       value=word_index[\"<PAD>\"],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0]), len(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  9 10  9 11 12 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91083"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(word_index.keys())\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 16)          1457328   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_3 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,457,617\n",
      "Trainable params: 1,457,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(len(train_data)/2.4)\n",
    "x_val = train_data[:split]\n",
    "partial_x_train = train_data[split:]\n",
    "\n",
    "y_val = train_labels[:split]\n",
    "partial_y_train = train_labels[split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_val.shape ->(88709, 256)\n",
      "partial_x_train.shape ->(124193, 256)\n",
      "y_val.shape ->(88709,)\n",
      "partial_y_train.shape ->(124193,)\n"
     ]
    }
   ],
   "source": [
    "print('x_val.shape ->'+str(x_val.shape))\n",
    "print('partial_x_train.shape ->'+str(partial_x_train.shape))\n",
    "print('y_val.shape ->'+str(y_val.shape))\n",
    "print('partial_y_train.shape ->'+str(partial_y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(212902,)"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124193 samples, validate on 88709 samples\n",
      "Epoch 1/40\n",
      "124193/124193 [==============================] - 10s 79us/step - loss: 0.3344 - acc: 0.9376 - val_loss: 0.1419 - val_acc: 0.9711\n",
      "Epoch 2/40\n",
      "124193/124193 [==============================] - 10s 78us/step - loss: 0.2272 - acc: 0.9376 - val_loss: 0.1392 - val_acc: 0.9711\n",
      "Epoch 3/40\n",
      "124193/124193 [==============================] - 10s 77us/step - loss: 0.2220 - acc: 0.9377 - val_loss: 0.1387 - val_acc: 0.9711\n",
      "Epoch 4/40\n",
      "124193/124193 [==============================] - 10s 78us/step - loss: 0.2113 - acc: 0.9382 - val_loss: 0.1313 - val_acc: 0.9709\n",
      "Epoch 5/40\n",
      "124193/124193 [==============================] - 10s 78us/step - loss: 0.1955 - acc: 0.9388 - val_loss: 0.1208 - val_acc: 0.9705\n",
      "Epoch 6/40\n",
      "124193/124193 [==============================] - 10s 78us/step - loss: 0.1804 - acc: 0.9394 - val_loss: 0.1066 - val_acc: 0.9703\n",
      "Epoch 7/40\n",
      "124193/124193 [==============================] - 10s 78us/step - loss: 0.1677 - acc: 0.9399 - val_loss: 0.0958 - val_acc: 0.9706\n",
      "Epoch 8/40\n",
      "124193/124193 [==============================] - 10s 78us/step - loss: 0.1566 - acc: 0.9406 - val_loss: 0.0860 - val_acc: 0.9712\n",
      "Epoch 9/40\n",
      "124193/124193 [==============================] - 10s 78us/step - loss: 0.1468 - acc: 0.9414 - val_loss: 0.0807 - val_acc: 0.9724\n",
      "Epoch 10/40\n",
      "124193/124193 [==============================] - 10s 78us/step - loss: 0.1380 - acc: 0.9423 - val_loss: 0.0780 - val_acc: 0.9734\n",
      "Epoch 11/40\n",
      "124193/124193 [==============================] - 10s 78us/step - loss: 0.1302 - acc: 0.9442 - val_loss: 0.0705 - val_acc: 0.9736\n",
      "Epoch 12/40\n",
      "124193/124193 [==============================] - 10s 78us/step - loss: 0.1234 - acc: 0.9463 - val_loss: 0.0668 - val_acc: 0.9746\n",
      "Epoch 13/40\n",
      "124193/124193 [==============================] - 10s 80us/step - loss: 0.1174 - acc: 0.9476 - val_loss: 0.0628 - val_acc: 0.9742\n",
      "Epoch 14/40\n",
      "124193/124193 [==============================] - 10s 79us/step - loss: 0.1126 - acc: 0.9487 - val_loss: 0.0613 - val_acc: 0.9764\n",
      "Epoch 15/40\n",
      "124193/124193 [==============================] - 9s 76us/step - loss: 0.1080 - acc: 0.9502 - val_loss: 0.0587 - val_acc: 0.9744\n",
      "Epoch 16/40\n",
      "124193/124193 [==============================] - 9s 75us/step - loss: 0.1044 - acc: 0.9519 - val_loss: 0.0563 - val_acc: 0.9772\n",
      "Epoch 17/40\n",
      "124193/124193 [==============================] - 9s 75us/step - loss: 0.1007 - acc: 0.9539 - val_loss: 0.0545 - val_acc: 0.9765\n",
      "Epoch 18/40\n",
      "124193/124193 [==============================] - 9s 75us/step - loss: 0.0973 - acc: 0.9556 - val_loss: 0.0523 - val_acc: 0.9784\n",
      "Epoch 19/40\n",
      "124193/124193 [==============================] - 9s 75us/step - loss: 0.0941 - acc: 0.9576 - val_loss: 0.0513 - val_acc: 0.9794\n",
      "Epoch 20/40\n",
      "124193/124193 [==============================] - 9s 75us/step - loss: 0.0912 - acc: 0.9587 - val_loss: 0.0499 - val_acc: 0.9785\n",
      "Epoch 21/40\n",
      "124193/124193 [==============================] - 9s 76us/step - loss: 0.0884 - acc: 0.9598 - val_loss: 0.0488 - val_acc: 0.9805\n",
      "Epoch 22/40\n",
      "124193/124193 [==============================] - 9s 76us/step - loss: 0.0857 - acc: 0.9608 - val_loss: 0.0479 - val_acc: 0.9798\n",
      "Epoch 23/40\n",
      "124193/124193 [==============================] - 9s 76us/step - loss: 0.0835 - acc: 0.9616 - val_loss: 0.0471 - val_acc: 0.9796\n",
      "Epoch 24/40\n",
      "124193/124193 [==============================] - 9s 76us/step - loss: 0.0806 - acc: 0.9633 - val_loss: 0.0484 - val_acc: 0.9781\n",
      "Epoch 25/40\n",
      "124193/124193 [==============================] - 9s 76us/step - loss: 0.0784 - acc: 0.9642 - val_loss: 0.0458 - val_acc: 0.9799\n",
      "Epoch 26/40\n",
      "124193/124193 [==============================] - 9s 76us/step - loss: 0.0760 - acc: 0.9656 - val_loss: 0.0465 - val_acc: 0.9790\n",
      "Epoch 27/40\n",
      "124193/124193 [==============================] - 9s 76us/step - loss: 0.0741 - acc: 0.9665 - val_loss: 0.0450 - val_acc: 0.9803\n",
      "Epoch 28/40\n",
      "124193/124193 [==============================] - 9s 76us/step - loss: 0.0723 - acc: 0.9676 - val_loss: 0.0453 - val_acc: 0.9795\n",
      "Epoch 29/40\n",
      "124193/124193 [==============================] - 10s 80us/step - loss: 0.0707 - acc: 0.9682 - val_loss: 0.0450 - val_acc: 0.9786\n",
      "Epoch 30/40\n",
      "124193/124193 [==============================] - 10s 79us/step - loss: 0.0691 - acc: 0.9690 - val_loss: 0.0450 - val_acc: 0.9786\n",
      "Epoch 31/40\n",
      "124193/124193 [==============================] - 10s 79us/step - loss: 0.0676 - acc: 0.9698 - val_loss: 0.0466 - val_acc: 0.9778\n",
      "Epoch 32/40\n",
      "124193/124193 [==============================] - 10s 79us/step - loss: 0.0665 - acc: 0.9703 - val_loss: 0.0463 - val_acc: 0.9788\n",
      "Epoch 33/40\n",
      "124193/124193 [==============================] - 10s 79us/step - loss: 0.0651 - acc: 0.9712 - val_loss: 0.0446 - val_acc: 0.9801\n",
      "Epoch 34/40\n",
      "124193/124193 [==============================] - 10s 80us/step - loss: 0.0639 - acc: 0.9715 - val_loss: 0.0477 - val_acc: 0.9778\n",
      "Epoch 35/40\n",
      "124193/124193 [==============================] - 10s 79us/step - loss: 0.0626 - acc: 0.9715 - val_loss: 0.0487 - val_acc: 0.9775\n",
      "Epoch 36/40\n",
      "124193/124193 [==============================] - 10s 81us/step - loss: 0.0615 - acc: 0.9726 - val_loss: 0.0547 - val_acc: 0.9754\n",
      "Epoch 37/40\n",
      "124193/124193 [==============================] - 10s 81us/step - loss: 0.0605 - acc: 0.9730 - val_loss: 0.0478 - val_acc: 0.9780\n",
      "Epoch 38/40\n",
      "124193/124193 [==============================] - 10s 81us/step - loss: 0.0595 - acc: 0.9732 - val_loss: 0.0516 - val_acc: 0.9767\n",
      "Epoch 39/40\n",
      "124193/124193 [==============================] - 10s 81us/step - loss: 0.0584 - acc: 0.9741 - val_loss: 0.0496 - val_acc: 0.9775\n",
      "Epoch 40/40\n",
      "124193/124193 [==============================] - 10s 82us/step - loss: 0.0578 - acc: 0.9743 - val_loss: 0.0502 - val_acc: 0.9775\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=40,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212220/212220 [==============================] - 3s 12us/step\n",
      "[0.1077612258531179, 0.9595655451889549]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data, test_labels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_review(texts, word_list):\n",
    "    idx_arrs = []\n",
    "    for text in texts:\n",
    "        word_arr = sentence_to_word_array(text)\n",
    "        idx_arr = np.zeros(256) # word_index[\"<PAD>\"]\n",
    "        for i, w in enumerate(word_arr):\n",
    "            idx_arr[i] = word_index[w]  \n",
    "        idx_arrs.append(idx_arr)\n",
    "    return np.array(idx_arrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = encode_review(['how are you doing today'], word_list)\n",
    "prediction = model.predict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00014148]], dtype=float32)"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256)"
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12919, 14470,   185, ...,     0,     0,     0],\n",
       "       [28542, 17920,   230, ...,     0,     0,     0],\n",
       "       [  230,   359,    21, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  227,    37,   337, ...,     0,     0,     0],\n",
       "       [   32,   116,  1924, ...,     0,     0,     0],\n",
       "       [17267,    12, 91078, ...,     0,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 78., 162.,  15., 251., 245.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.]])"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
