{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/gist/absin1/b90f9eba8c0dec5d0e2391253df768ee/copy-of-transfer-learning-semantic-similarity-with-tf-hub-universal-encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "co7MV6sX7Xto"
   },
   "source": [
    "# [Keras + Universal Sentence Encoder = Transfer Learning for text data](https://www.dlology.com/blog/keras-meets-universal-sentence-encoder-transfer-learning-for-text-data/) Tutorial\n",
    "## Universal Sentence Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eAVQGidpL8v5"
   },
   "source": [
    "This notebook illustrates how to access the Universal Sentence Encoder and use it for sentence similarity and sentence classification tasks.\n",
    "\n",
    "The Universal Sentence Encoder makes getting sentence level embeddings as easy as it has historically been to lookup the embeddings for individual words. The sentence embeddings can then be trivially used to compute sentence level meaning similarity as well as to enable better performance on downstream classification tasks using less supervised training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pOTzp8O36CyQ"
   },
   "source": [
    "# Getting Started\n",
    "\n",
    "This section sets up the environment for access to the Universal Sentence Encoder on TF Hub and provides examples of applying the encoder to words, sentences, and paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "lVjNK8shFKOC",
    "outputId": "68ee523a-0710-4180-e9f2-9551c3644fce"
   },
   "outputs": [],
   "source": [
    "# Install the latest Tensorflow version.\n",
    "!pip3 install --quiet \"tensorflow>=1.7\"\n",
    "# Install TF-Hub.\n",
    "!pip3 install --quiet tensorflow-hub\n",
    "!pip3 install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "63Pd3nJnTl-i"
   },
   "source": [
    "More detailed information about installing Tensorflow can be found at [https://www.tensorflow.org/install/](https://www.tensorflow.org/install/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MSeY-MUQo2Ha",
    "outputId": "22061b32-6fab-4286-fd44-467ec32c0ea8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/andy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/andy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/andy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/andy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/andy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/andy/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/andy/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/andy/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/andy/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/andy/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/andy/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import keras.layers as layers\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zwty8Z6mAkdV"
   },
   "outputs": [],
   "source": [
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "Q8F4LNGFqOiq",
    "outputId": "1b670b96-6d94-4f2a-c935-730e7e79d0db"
   },
   "outputs": [],
   "source": [
    "# Import the Universal Sentence Encoder's TF Hub module\n",
    "embed = hub.Module(module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "O2cYc2WEkSGP",
    "outputId": "653fe78a-2288-40a7-da49-2f1cf0d8f2a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_size = embed.get_output_info_dict()['default'].get_shape()[1].value\n",
    "embed_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "MElqkcDiDKsp",
    "outputId": "4e40f6e5-8532-4f0d-83ed-04670cb5936d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andy/.local/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26915</th>\n",
       "      <td>worry</td>\n",
       "      <td>yup our coke blades b annnd now i only need th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37746</th>\n",
       "      <td>happiness</td>\n",
       "      <td>having a cup of tea i have a cold so it's tast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15211</th>\n",
       "      <td>worry</td>\n",
       "      <td>sucks about your cat... hope you guys feel better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8556</th>\n",
       "      <td>surprise</td>\n",
       "      <td>wow their is no pancake mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28397</th>\n",
       "      <td>neutral</td>\n",
       "      <td>hey there what's up?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label                                               text\n",
       "26915      worry  yup our coke blades b annnd now i only need th...\n",
       "37746  happiness  having a cup of tea i have a cold so it's tast...\n",
       "15211      worry  sucks about your cat... hope you guys feel better\n",
       "8556    surprise                        wow their is no pancake mix\n",
       "28397    neutral                               hey there what's up?"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas.io.sql as sqlio\n",
    "import numpy as np\n",
    "\n",
    "def get_dataframe_sql():\n",
    "    df = None\n",
    "    sql = \"select emotion as label, text_ as text from dataset_emotion_only\"\n",
    "    con = None\n",
    "    try:\n",
    "        con = psycopg2.connect(\"host='35.200.234.61' dbname='sales' user='postgres' password='cx6ac54nmgGtLD1y'\")\n",
    "        df = sqlio.read_sql_query(sql, con)\n",
    "    except psycopg2.DatabaseError as e:\n",
    "        if con:\n",
    "            con.rollback()\n",
    "        print(e)\n",
    "        sys.exit(1)\n",
    "    finally:\n",
    "        if con:\n",
    "            con.close()\n",
    "    df = df.sample(frac=1.0)\n",
    "    df.label = df.label.astype('category')\n",
    "    return df\n",
    "  \n",
    "df = get_dataframe_sql()\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "df_train = df[msk]\n",
    "df_test = df[~msk]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3HAtd4X5DayF",
    "outputId": "036ef7da-6034-4d2e-de61-88352c9d4a5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_counts = len(df_train.label.cat.categories)\n",
    "category_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sf9A4Xl6J7c6"
   },
   "source": [
    "## Wrap embed module in a Lambda layer\n",
    "Explicitly cast the input as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PRD3fWgJjOrP"
   },
   "outputs": [],
   "source": [
    "def UniversalEmbedding(x):\n",
    "    return embed(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "t3fllZkVjXKV",
    "outputId": "528eb185-4454-4ba3-91d2-bd6c5733858e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 14)                3598      \n",
      "=================================================================\n",
      "Total params: 134,926\n",
      "Trainable params: 134,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_text = layers.Input(shape=(1,), dtype=tf.string)\n",
    "embedding = layers.Lambda(UniversalEmbedding, output_shape=(embed_size,))(input_text)\n",
    "dense = layers.Dense(256, activation='relu')(embedding)\n",
    "pred = layers.Dense(category_counts, activation='sigmoid')(dense)\n",
    "model = Model(inputs=[input_text], outputs=pred)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Ube1DvYEJ3q"
   },
   "outputs": [],
   "source": [
    "train_text = df_train['text'].tolist()\n",
    "train_text = np.array(train_text, dtype=object)[:, np.newaxis]\n",
    "\n",
    "train_label = np.asarray(pd.get_dummies(df_train.label), dtype = np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WX3s8yIVFWHI",
    "outputId": "ca52083b-e89b-414f-e13c-218c3626cafc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31866, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9PfsPdG8FZBI",
    "outputId": "cebbb4b4-0d8c-45b0-f0e3-58f491bbe593"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31866, 14)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "gPYVmBr2Fbob",
    "outputId": "ae33f202-e1a3-4d2b-c02f-6feebdeccf75"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]], dtype=int8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QWAjtjdeI9P4"
   },
   "outputs": [],
   "source": [
    "test_text = df_test['text'].tolist()\n",
    "test_text = np.array(test_text, dtype=object)[:, np.newaxis]\n",
    "test_label = np.asarray(pd.get_dummies(df_test.label), dtype = np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bqcRy_JWXe0u"
   },
   "source": [
    "## Train Keras model and save weights\n",
    "This only train and save our Keras layers not the embed module' weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "_stfC_7VFhS8",
    "outputId": "3b297de8-1c24-42bc-9272-912ac036c9c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31866 samples, validate on 8134 samples\n",
      "Epoch 1/1\n",
      "   64/31866 [..............................] - ETA: 6:43 - loss: 0.6923 - acc: 0.5078 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7fe17ae8eac8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/andy/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1473, in __del__\n",
      "    self._session._session, self._handle)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: (None, None, 'Session has been closed.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31840/31866 [============================>.] - ETA: 0s - loss: 0.2103 - acc: 0.9279"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7fe17b24ac50>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/andy/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1473, in __del__\n",
      "    self._session._session, self._handle)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: (None, None, 'Session has been closed.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "31866/31866 [==============================] - 123s 4ms/step - loss: 0.2103 - acc: 0.9279 - val_loss: 0.1942 - val_acc: 0.9298\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    session.run(tf.tables_initializer())\n",
    "    history = model.fit(train_text, \n",
    "            train_label,\n",
    "            validation_data=(test_text, test_label),\n",
    "            epochs=1,\n",
    "            batch_size=32)\n",
    "    model.save_weights('../model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "UW1CiBhnXnxa",
    "outputId": "1c9f90b9-3757-461e-d06e-076e524bd792"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 andy andy 542K Aug  8 12:50 model.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls -alh | grep model.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nQux6qLdXabG"
   },
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "fSDxetlfUEiD",
    "outputId": "fd01489b-e59c-48ed-dcd4-34e815d3f3ca"
   },
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "\n",
    "K.set_session(session)\n",
    "session.run(tf.global_variables_initializer())\n",
    "session.run(tf.tables_initializer())\n",
    "model.load_weights('./model.h5')\n",
    "    #predicts = model.predict(new_text, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = [\"Ma chud gayi hai\",\"This is not exciting at all\", \"I don't like you at all\",  \"You forgot to mention just how smart the jews are, next they will make a deadly virus to kill ALL people BUT the jews!\"]\n",
    "new_text = np.array(new_text, dtype=object)[:, np.newaxis]\n",
    "predicts = model.predict(new_text, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.94555521e-03, 2.32979655e-03, 2.25734413e-02, 1.48974359e-02,\n",
       "        2.17680931e-02, 4.53250110e-02, 1.69878900e-02, 2.62952149e-02,\n",
       "        3.95895898e-01, 8.30665231e-03, 5.09114563e-02, 1.37567520e-04,\n",
       "        4.24551368e-02, 2.08949894e-01],\n",
       "       [7.38626719e-03, 1.60430074e-02, 2.97409892e-02, 1.76334083e-02,\n",
       "        2.13314891e-02, 6.19596243e-02, 1.04850560e-01, 1.70007944e-02,\n",
       "        7.22412467e-02, 3.21382284e-02, 1.49075031e-01, 7.92920589e-04,\n",
       "        9.80421603e-02, 2.89799392e-01],\n",
       "       [4.46453691e-03, 5.53172827e-03, 2.15744674e-02, 1.10730231e-02,\n",
       "        7.90318847e-03, 1.44430697e-02, 1.81470037e-01, 1.09797716e-01,\n",
       "        1.33736938e-01, 8.15975666e-03, 2.01272994e-01, 2.54780054e-04,\n",
       "        2.93026567e-02, 1.81697428e-01],\n",
       "       [1.74095929e-02, 1.04933679e-02, 5.26147783e-02, 4.24410999e-02,\n",
       "        8.89391899e-02, 7.04200864e-02, 9.77967083e-02, 2.25252807e-02,\n",
       "        2.65968412e-01, 3.93825471e-02, 1.81784034e-02, 1.77690387e-03,\n",
       "        9.07517374e-02, 2.82140791e-01]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yyDGVtigW57f",
    "outputId": "6cdbf287-9c0b-433a-da7d-cfcc7805405e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neutral', 'worry', 'sadness', 'worry']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = df_train.label.cat.categories.tolist()\n",
    "predict_logits = predicts.argmax(axis=1)\n",
    "predict_labels = [categories[logit] for logit in predict_logits]\n",
    "predict_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ma chud gayi hai--->']\n",
      "\tneutral--->0.3958959\n",
      "\tworry--->0.2089499\n",
      "['This is not exciting at all--->']\n",
      "\thate--->0.10485056\n",
      "\tsadness--->0.14907503\n",
      "\tworry--->0.2897994\n",
      "[\"I don't like you at all--->\"]\n",
      "\thate--->0.18147004\n",
      "\tlove--->0.109797716\n",
      "\tneutral--->0.13373694\n",
      "\tsadness--->0.201273\n",
      "\tworry--->0.18169743\n",
      "['You forgot to mention just how smart the jews are, next they will make a deadly virus to kill ALL people BUT the jews!--->']\n",
      "\tneutral--->0.2659684\n",
      "\tworry--->0.2821408\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.1\n",
    "for i,sentence in enumerate(new_text):\n",
    "    predict = predicts[i]\n",
    "    print(sentence+'--->')\n",
    "    for j, pred in enumerate(predict):\n",
    "        if pred>threshold:\n",
    "            print('\\t'+categories[j]+'--->'+str(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9097289443016052\n",
      "0.9343648850917816\n",
      "0.8165875226259232\n"
     ]
    }
   ],
   "source": [
    "for predict in predicts:\n",
    "    sum = 0\n",
    "    for j, pred in enumerate(predict):\n",
    "        sum += pred\n",
    "    print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/andy/git/ai/notebooks'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/andy/git/ai\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI-Flask.postman_collection.json  \u001b[0m\u001b[01;34mlib\u001b[0m/       \u001b[01;34mnotebooks\u001b[0m/  \u001b[01;34mstatic\u001b[0m/  wsgi.py\r\n",
      "\u001b[01;34mbenchmark\u001b[0m/                        model.h5   setup.sh    \u001b[01;34mtext\u001b[0m/\r\n",
      "constants.yaml                    \u001b[01;32mngrok.sh\u001b[0m*  \u001b[01;34mspeech\u001b[0m/     web.py\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andy/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data=yaml.load(open('constants.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./model.h5'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['emotion_detection']['model_weights_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andy/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "config=yaml.load(open('/home/andy/git/ai/constants.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "host=config['emotion']['db_host']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['emotion']['threshold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Copy of Transfer Learning - Semantic Similarity with TF-Hub Universal Encoder",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
