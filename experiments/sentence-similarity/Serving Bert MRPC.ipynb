{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/absin/git/ai/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/absin/git/ai/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/absin/git/ai/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/absin/git/ai/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/absin/git/ai/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/absin/git/ai/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/absin/git/ai/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/absin/git/ai/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/absin/git/ai/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/absin/git/ai/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/absin/git/ai/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/absin/git/ai/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0903 20:14:53.935834 140530993456960 deprecation_wrapper.py:119] From bert_repo/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "#!test -d bert_repo || git clone https://github.com/google-research/bert bert_repo\n",
    "if not 'bert_repo' in sys.path:\n",
    "  sys.path += ['bert_repo']\n",
    "\n",
    "# import python modules defined by BERT\n",
    "import modeling\n",
    "import optimization\n",
    "import run_classifier\n",
    "import run_classifier_with_tfhub\n",
    "import tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Task data directory: glue_data/MRPC *****\n",
      "dev_ids.tsv  msr_paraphrase_test.txt   test.tsv\r\n",
      "dev.tsv      msr_paraphrase_train.txt  train.tsv\r\n"
     ]
    }
   ],
   "source": [
    "TASK = 'MRPC' #@param {type:\"string\"}\n",
    "assert TASK in ('MRPC', 'CoLA'), 'Only (MRPC, CoLA) are demonstrated here.'\n",
    "\n",
    "# Download glue data.\n",
    "#!test -d download_glue_repo || git clone https://gist.github.com/60c2bdb54d156a41194446737ce03e2e.git download_glue_repo\n",
    "#!python download_glue_repo/download_glue_data.py --data_dir='glue_data' --tasks=$TASK\n",
    "\n",
    "TASK_DATA_DIR = 'glue_data/' + TASK\n",
    "print('***** Task data directory: {} *****'.format(TASK_DATA_DIR))\n",
    "!ls $TASK_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0903 20:16:46.625719 140530993456960 deprecation_wrapper.py:119] From bert_repo/run_classifier_with_tfhub.py:151: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0903 20:16:47.102885 140530993456960 deprecation_wrapper.py:119] From bert_repo/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'here',\n",
       " \"'\",\n",
       " 's',\n",
       " 'an',\n",
       " 'example',\n",
       " 'of',\n",
       " 'using',\n",
       " 'the',\n",
       " 'B',\n",
       " '##ER',\n",
       " '##T',\n",
       " 'token',\n",
       " '##izer']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT_MODEL = 'cased_L-12_H-768_A-12' #@param {type:\"string\"}\n",
    "BERT_MODEL_HUB = 'https://tfhub.dev/google/bert_' + BERT_MODEL + '/1'\n",
    "tokenizer = run_classifier_with_tfhub.create_tokenizer_from_hub_module(BERT_MODEL_HUB)\n",
    "tokenizer.tokenize(\"This here's an example of using the BERT tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 128\n",
    "processor = run_classifier.MrpcProcessor()\n",
    "label_list = processor.get_labels()\n",
    "prediction_examples = processor.get_dev_examples(TASK_DATA_DIR)[:8]\n",
    "input_features = run_classifier.convert_examples_to_features(prediction_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 128\n",
    "processor = run_classifier.MrpcProcessor()\n",
    "label_list = processor.get_labels()\n",
    "prediction_examples = []\n",
    "prediction_examples.append(run_classifier.InputExample(guid='###231232', text_a='Good evening', text_b='Good afternoon', label='1'))\n",
    "input_features = run_classifier.convert_examples_to_features(prediction_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.0023771962\t0.9976228\n",
      "-------\n",
      "0\n",
      "0.9963199\t0.0036800979\n",
      "-------\n",
      "0\n",
      "0.14532445\t0.85467553\n",
      "-------\n",
      "1\n",
      "0.002536964\t0.997463\n",
      "-------\n",
      "0\n",
      "0.99533373\t0.0046662455\n",
      "-------\n",
      "1\n",
      "0.002593101\t0.9974069\n",
      "-------\n",
      "0\n",
      "0.0033952503\t0.9966048\n",
      "-------\n",
      "1\n",
      "0.0024598227\t0.99754024\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    with tf.Session() as sess:\n",
    "        tf.saved_model.loader.load(sess, [tag_constants.SERVING], \"/home/absin/Downloads/content/export_t/1566219509\")\n",
    "        tensor_input_ids = graph.get_tensor_by_name('input_ids_1:0')\n",
    "        tensor_input_mask = graph.get_tensor_by_name('input_mask_1:0')\n",
    "        tensor_label_ids = graph.get_tensor_by_name('label_ids_1:0')\n",
    "        tensor_segment_ids = graph.get_tensor_by_name('segment_ids_1:0')\n",
    "        tensor_outputs = graph.get_tensor_by_name('loss/Softmax:0')\n",
    "        for i,input_feature in enumerate(input_features):\n",
    "            input_ids = np.array(input_feature.input_ids).reshape(-1, 128)\n",
    "            input_mask = np.array(input_feature.input_mask).reshape(-1, 128)\n",
    "            label_ids = np.array(input_feature.label_id)\n",
    "            segment_ids = np.array(input_feature.segment_ids).reshape(-1, 128)\n",
    "            result = sess.run(tensor_outputs, feed_dict={\n",
    "                    tensor_input_ids: input_ids,\n",
    "                    tensor_input_mask: input_mask,\n",
    "                    tensor_label_ids: [],\n",
    "                    tensor_segment_ids: segment_ids,\n",
    "                })\n",
    "            print(prediction_examples[i].label)\n",
    "            print(*(result[0]), sep='\\t')\n",
    "            print('-------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128)\n",
      "0.0024648812\t0.9975351\n",
      "-------\n",
      "(1, 128)\n",
      "0.002424499\t0.99757546\n",
      "-------\n",
      "(1, 128)\n",
      "0.002491034\t0.997509\n",
      "-------\n",
      "(1, 128)\n",
      "0.0025251713\t0.99747485\n",
      "-------\n",
      "(1, 128)\n",
      "0.0024491025\t0.9975509\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    with tf.Session() as sess:\n",
    "        tf.saved_model.loader.load(sess, [tag_constants.SERVING], \"/home/absin/Downloads/content/export_t/1566219509\")\n",
    "        tensor_input_ids = graph.get_tensor_by_name('input_ids_1:0')\n",
    "        tensor_input_mask = graph.get_tensor_by_name('input_mask_1:0')\n",
    "        tensor_label_ids = graph.get_tensor_by_name('label_ids_1:0')\n",
    "        tensor_segment_ids = graph.get_tensor_by_name('segment_ids_1:0')\n",
    "        tensor_outputs = graph.get_tensor_by_name('loss/Softmax:0')\n",
    "        record_iterator = tf.python_io.tf_record_iterator(path=\"/home/absin/git/bert_repo/tf_examples_1.tfrecord\")\n",
    "        for string_record in record_iterator:\n",
    "            example = tf.train.Example()\n",
    "            example.ParseFromString(string_record)\n",
    "            input_ids = example.features.feature['input_ids'].int64_list.value\n",
    "            input_mask = example.features.feature['input_mask'].int64_list.value\n",
    "            label_ids = example.features.feature['label_ids'].int64_list.value\n",
    "            segment_ids = example.features.feature['segment_ids'].int64_list.value\n",
    "            print(np.array(segment_ids).reshape(-1, 128).shape)\n",
    "            result = sess.run(tensor_outputs, feed_dict={\n",
    "                    tensor_input_ids: np.array(input_ids).reshape(-1, 128),\n",
    "                    tensor_input_mask: np.array(input_mask).reshape(-1, 128),\n",
    "                    tensor_label_ids: np.array(label_ids),\n",
    "                    tensor_segment_ids: np.array(segment_ids).reshape(-1, 128),\n",
    "                })\n",
    "            print(*(result[0]), sep='\\t')\n",
    "            print('-------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
