{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/gist/absin1/b90f9eba8c0dec5d0e2391253df768ee/copy-of-transfer-learning-semantic-similarity-with-tf-hub-universal-encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "co7MV6sX7Xto"
   },
   "source": [
    "# [Keras + Universal Sentence Encoder = Transfer Learning for text data](https://www.dlology.com/blog/keras-meets-universal-sentence-encoder-transfer-learning-for-text-data/) Tutorial\n",
    "## Universal Sentence Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eAVQGidpL8v5"
   },
   "source": [
    "This notebook illustrates how to access the Universal Sentence Encoder and use it for sentence similarity and sentence classification tasks.\n",
    "\n",
    "The Universal Sentence Encoder makes getting sentence level embeddings as easy as it has historically been to lookup the embeddings for individual words. The sentence embeddings can then be trivially used to compute sentence level meaning similarity as well as to enable better performance on downstream classification tasks using less supervised training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pOTzp8O36CyQ"
   },
   "source": [
    "# Getting Started\n",
    "\n",
    "This section sets up the environment for access to the Universal Sentence Encoder on TF Hub and provides examples of applying the encoder to words, sentences, and paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "lVjNK8shFKOC",
    "outputId": "68ee523a-0710-4180-e9f2-9551c3644fce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /home/absin/git/ai/venv/lib/python3.6/site-packages (0.9.0)\r\n",
      "Requirement already satisfied: scipy>=0.14.0 in /home/absin/git/ai/venv/lib/python3.6/site-packages (from seaborn) (1.3.0)\r\n",
      "Requirement already satisfied: matplotlib>=1.4.3 in /home/absin/git/ai/venv/lib/python3.6/site-packages (from seaborn) (3.1.1)\r\n",
      "Requirement already satisfied: pandas>=0.15.2 in /home/absin/git/ai/venv/lib/python3.6/site-packages (from seaborn) (0.25.0)\r\n",
      "Requirement already satisfied: numpy>=1.9.3 in /home/absin/git/ai/venv/lib/python3.6/site-packages (from seaborn) (1.17.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /home/absin/git/ai/venv/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/absin/git/ai/venv/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (2.8.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/absin/git/ai/venv/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (1.1.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/absin/git/ai/venv/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (2.4.2)\r\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/absin/git/ai/venv/lib/python3.6/site-packages (from pandas>=0.15.2->seaborn) (2019.2)\r\n",
      "Requirement already satisfied: six in /home/absin/git/ai/venv/lib/python3.6/site-packages (from cycler>=0.10->matplotlib>=1.4.3->seaborn) (1.12.0)\r\n",
      "Requirement already satisfied: setuptools in /home/absin/git/ai/venv/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (41.0.1)\r\n"
     ]
    }
   ],
   "source": [
    "# Install the latest Tensorflow version.\n",
    "!pip3 install --quiet \"tensorflow>=1.7\"\n",
    "# Install TF-Hub.\n",
    "!pip3 install --quiet tensorflow-hub\n",
    "!pip3 install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "63Pd3nJnTl-i"
   },
   "source": [
    "More detailed information about installing Tensorflow can be found at [https://www.tensorflow.org/install/](https://www.tensorflow.org/install/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MSeY-MUQo2Ha",
    "outputId": "22061b32-6fab-4286-fd44-467ec32c0ea8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/absin/git/ai/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/absin/git/ai/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/absin/git/ai/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/absin/git/ai/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/absin/git/ai/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/absin/git/ai/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/absin/git/ai/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/absin/git/ai/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/absin/git/ai/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/absin/git/ai/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/absin/git/ai/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/absin/git/ai/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import keras.layers as layers\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zwty8Z6mAkdV"
   },
   "outputs": [],
   "source": [
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "Q8F4LNGFqOiq",
    "outputId": "1b670b96-6d94-4f2a-c935-730e7e79d0db"
   },
   "outputs": [],
   "source": [
    "# Import the Universal Sentence Encoder's TF Hub module\n",
    "embed = hub.Module(module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "O2cYc2WEkSGP",
    "outputId": "653fe78a-2288-40a7-da49-2f1cf0d8f2a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_size = embed.get_output_info_dict()['default'].get_shape()[1].value\n",
    "embed_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "MElqkcDiDKsp",
    "outputId": "4e40f6e5-8532-4f0d-83ed-04670cb5936d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6312</th>\n",
       "      <td>relief</td>\n",
       "      <td>cause i wasn't there</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11747</th>\n",
       "      <td>worry</td>\n",
       "      <td>i really hope my parents don't make me stay ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36812</th>\n",
       "      <td>happiness</td>\n",
       "      <td>that's part of what i've been working on...use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2384</th>\n",
       "      <td>happiness</td>\n",
       "      <td>come hang out wif meeee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23631</th>\n",
       "      <td>worry</td>\n",
       "      <td>oooh... that's right by the zoo... think... in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label                                               text\n",
       "6312      relief                               cause i wasn't there\n",
       "11747      worry  i really hope my parents don't make me stay ho...\n",
       "36812  happiness  that's part of what i've been working on...use...\n",
       "2384   happiness                            come hang out wif meeee\n",
       "23631      worry  oooh... that's right by the zoo... think... in..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas.io.sql as sqlio\n",
    "import numpy as np\n",
    "\n",
    "def get_dataframe_sql():\n",
    "    df = None\n",
    "    sql = \"select emotion as label, text_ as text from dataset_emotion_only\"\n",
    "    con = None\n",
    "    try:\n",
    "        con = psycopg2.connect(\"host='35.200.234.61' dbname='sales' user='postgres' password='cx6ac54nmgGtLD1y'\")\n",
    "        df = sqlio.read_sql_query(sql, con)\n",
    "    except psycopg2.DatabaseError as e:\n",
    "        if con:\n",
    "            con.rollback()\n",
    "        print(e)\n",
    "        sys.exit(1)\n",
    "    finally:\n",
    "        if con:\n",
    "            con.close()\n",
    "    df = df.sample(frac=1.0)\n",
    "    df.label = df.label.astype('category')\n",
    "    return df\n",
    "  \n",
    "df = get_dataframe_sql()\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "df_train = df[msk]\n",
    "df_test = df[~msk]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3HAtd4X5DayF",
    "outputId": "036ef7da-6034-4d2e-de61-88352c9d4a5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_counts = len(df_train.label.cat.categories)\n",
    "category_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sf9A4Xl6J7c6"
   },
   "source": [
    "## Wrap embed module in a Lambda layer\n",
    "Explicitly cast the input as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PRD3fWgJjOrP"
   },
   "outputs": [],
   "source": [
    "def UniversalEmbedding(x):\n",
    "    return embed(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "t3fllZkVjXKV",
    "outputId": "528eb185-4454-4ba3-91d2-bd6c5733858e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 14)                3598      \n",
      "=================================================================\n",
      "Total params: 134,926\n",
      "Trainable params: 134,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_text = layers.Input(shape=(1,), dtype=tf.string)\n",
    "embedding = layers.Lambda(UniversalEmbedding, output_shape=(embed_size,))(input_text)\n",
    "dense = layers.Dense(256, activation='relu')(embedding)\n",
    "pred = layers.Dense(category_counts, activation='sigmoid')(dense)\n",
    "model = Model(inputs=[input_text], outputs=pred)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Ube1DvYEJ3q"
   },
   "outputs": [],
   "source": [
    "train_text = df_train['text'].tolist()\n",
    "train_text = np.array(train_text, dtype=object)[:, np.newaxis]\n",
    "\n",
    "train_label = np.asarray(pd.get_dummies(df_train.label), dtype = np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WX3s8yIVFWHI",
    "outputId": "ca52083b-e89b-414f-e13c-218c3626cafc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31866, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9PfsPdG8FZBI",
    "outputId": "cebbb4b4-0d8c-45b0-f0e3-58f491bbe593"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31866, 14)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "gPYVmBr2Fbob",
    "outputId": "ae33f202-e1a3-4d2b-c02f-6feebdeccf75"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]], dtype=int8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QWAjtjdeI9P4"
   },
   "outputs": [],
   "source": [
    "test_text = df_test['text'].tolist()\n",
    "test_text = np.array(test_text, dtype=object)[:, np.newaxis]\n",
    "test_label = np.asarray(pd.get_dummies(df_test.label), dtype = np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bqcRy_JWXe0u"
   },
   "source": [
    "## Train Keras model and save weights\n",
    "This only train and save our Keras layers not the embed module' weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "_stfC_7VFhS8",
    "outputId": "3b297de8-1c24-42bc-9272-912ac036c9c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31866 samples, validate on 8134 samples\n",
      "Epoch 1/5\n",
      "   32/31866 [..............................] - ETA: 18:10 - loss: 0.6967 - acc: 0.4330"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7fa034547860>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/absin/git/ai/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1473, in __del__\n",
      "    self._session._session, self._handle)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: (None, None, 'Session has been closed.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31840/31866 [============================>.] - ETA: 0s - loss: 0.2098 - acc: 0.9280"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7fa0344ff6d8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/absin/git/ai/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1473, in __del__\n",
      "    self._session._session, self._handle)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: (None, None, 'Session has been closed.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31866/31866 [==============================] - 191s 6ms/step - loss: 0.2098 - acc: 0.9280 - val_loss: 0.1946 - val_acc: 0.9298\n",
      "Epoch 2/5\n",
      "31866/31866 [==============================] - 193s 6ms/step - loss: 0.1901 - acc: 0.9300 - val_loss: 0.1930 - val_acc: 0.9299\n",
      "Epoch 3/5\n",
      "31866/31866 [==============================] - 188s 6ms/step - loss: 0.1883 - acc: 0.9305 - val_loss: 0.1925 - val_acc: 0.9299\n",
      "Epoch 4/5\n",
      "31866/31866 [==============================] - 191s 6ms/step - loss: 0.1865 - acc: 0.9309 - val_loss: 0.1924 - val_acc: 0.9300\n",
      "Epoch 5/5\n",
      "31866/31866 [==============================] - 194s 6ms/step - loss: 0.1849 - acc: 0.9312 - val_loss: 0.1921 - val_acc: 0.9302\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    session.run(tf.tables_initializer())\n",
    "    history = model.fit(train_text, \n",
    "            train_label,\n",
    "            validation_data=(test_text, test_label),\n",
    "            epochs=5,\n",
    "            batch_size=32)\n",
    "    model.save_weights('./model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "UW1CiBhnXnxa",
    "outputId": "1c9f90b9-3757-461e-d06e-076e524bd792"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 absin absin 542K Aug  7 19:26 model.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls -alh | grep model.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nQux6qLdXabG"
   },
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "fSDxetlfUEiD",
    "outputId": "fd01489b-e59c-48ed-dcd4-34e815d3f3ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7f9fed581668>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/absin/git/ai/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1473, in __del__\n",
      "    self._session._session, self._handle)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: (None, None, 'Session has been closed.')\n"
     ]
    }
   ],
   "source": [
    "new_text = [\"This is not exciting at all\", \"I don't like you at all\",  \"You forgot to mention just how smart the jews are, next they will make a deadly virus to kill ALL people BUT the jews!\"]\n",
    "new_text = np.array(new_text, dtype=object)[:, np.newaxis]\n",
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    session.run(tf.tables_initializer())\n",
    "    model.load_weights('./model.h5')  \n",
    "    predicts = model.predict(new_text, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.9935241e-03, 2.6679993e-02, 3.1930655e-02, 1.1398077e-02,\n",
       "        1.6420335e-02, 3.7594557e-02, 8.9221299e-02, 9.7981691e-03,\n",
       "        1.1691126e-01, 1.3052076e-02, 1.4867631e-01, 6.0796738e-05,\n",
       "        1.1503479e-01, 2.8995711e-01],\n",
       "       [3.4394264e-03, 5.5623055e-04, 1.9120693e-02, 4.9242675e-03,\n",
       "        2.2919476e-03, 3.5048723e-03, 2.4454299e-01, 1.1750087e-01,\n",
       "        1.6075274e-01, 2.2898614e-03, 2.3797655e-01, 6.7353249e-06,\n",
       "        1.7250627e-02, 1.2020707e-01],\n",
       "       [4.9343407e-03, 2.3430586e-04, 2.6564270e-02, 8.7498128e-03,\n",
       "        4.7906399e-02, 7.4281305e-02, 1.3324383e-01, 7.9410076e-03,\n",
       "        1.5347946e-01, 1.7086059e-02, 2.3347706e-02, 3.1292439e-05,\n",
       "        7.0502877e-02, 2.4828486e-01]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yyDGVtigW57f",
    "outputId": "6cdbf287-9c0b-433a-da7d-cfcc7805405e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['worry', 'hate', 'worry']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = df_train.label.cat.categories.tolist()\n",
    "predict_logits = predicts.argmax(axis=1)\n",
    "predict_labels = [categories[logit] for logit in predict_logits]\n",
    "predict_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is not exciting at all--->']\n",
      "\tneutral--->0.11691126\n",
      "\tsadness--->0.1486763\n",
      "\tsurprise--->0.11503479\n",
      "\tworry--->0.2899571\n",
      "[\"I don't like you at all--->\"]\n",
      "\thate--->0.24454299\n",
      "\tlove--->0.11750087\n",
      "\tneutral--->0.16075274\n",
      "\tsadness--->0.23797655\n",
      "\tworry--->0.12020707\n",
      "['You forgot to mention just how smart the jews are, next they will make a deadly virus to kill ALL people BUT the jews!--->']\n",
      "\thate--->0.13324383\n",
      "\tneutral--->0.15347946\n",
      "\tworry--->0.24828486\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.1\n",
    "for i,sentence in enumerate(new_text):\n",
    "    predict = predicts[i]\n",
    "    print(sentence+'--->')\n",
    "    for j, pred in enumerate(predict):\n",
    "        if pred>threshold:\n",
    "            print('\\t'+categories[j]+'--->'+str(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9097289443016052\n",
      "0.9343648850917816\n",
      "0.8165875226259232\n"
     ]
    }
   ],
   "source": [
    "for predict in predicts:\n",
    "    sum = 0\n",
    "    for j, pred in enumerate(predict):\n",
    "        sum += pred\n",
    "    print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Copy of Transfer Learning - Semantic Similarity with TF-Hub Universal Encoder",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
