{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import shlex\n",
    "import subprocess\n",
    "import sys\n",
    "import wave\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepspeech import Model, printVersions\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from shhlex import quote\n",
    "except ImportError:\n",
    "    from pipes import quote\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sample rate for audio\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "# These constants control the beam search decoder\n",
    "\n",
    "# Beam width used in the CTC decoder when building candidate transcriptions\n",
    "BEAM_WIDTH = 500\n",
    "\n",
    "# The alpha hyperparameter of the CTC decoder. Language Model weight\n",
    "LM_ALPHA = 0.75\n",
    "\n",
    "# The beta hyperparameter of the CTC decoder. Word insertion bonus.\n",
    "LM_BETA = 1.85\n",
    "\n",
    "\n",
    "# These constants are tied to the shape of the graph used (changing them changes\n",
    "# the geometry of the first layer), so make sure you use the same constants that\n",
    "# were used during training\n",
    "\n",
    "# Number of MFCC features to use\n",
    "N_FEATURES = 26\n",
    "\n",
    "# Size of the context window used for producing timesteps in the input vector\n",
    "N_CONTEXT = 9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_samplerate(audio_path):\n",
    "    sox_cmd = 'sox {} --type raw --bits 16 --channels 1 --rate {} --encoding signed-integer --endian little --compression 0.0 --no-dither - '.format(quote(audio_path), SAMPLE_RATE)\n",
    "    try:\n",
    "        output = subprocess.check_output(shlex.split(sox_cmd), stderr=subprocess.PIPE)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        raise RuntimeError('SoX returned non-zero status: {}'.format(e.stderr))\n",
    "    except OSError as e:\n",
    "        raise OSError(e.errno, 'SoX not found, use {}hz files or install it: {}'.format(SAMPLE_RATE, e.strerror))\n",
    "\n",
    "    return SAMPLE_RATE, np.frombuffer(output, np.int16)\n",
    "\n",
    "\n",
    "def metadata_to_string(metadata):\n",
    "    return ''.join(item.character for item in metadata.items)\n",
    "\n",
    "\n",
    "class VersionAction(argparse.Action):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(VersionAction, self).__init__(nargs=0, *args, **kwargs)\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        printVersions()\n",
    "        exit(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = '/home/absin/Downloads/deepspeech-0.5.1-models/alphabet.txt'\n",
    "model = '/home/absin/Downloads/deepspeech-0.5.1-models/output_graph.pb'\n",
    "lm = '/home/absin/Downloads/deepspeech-0.5.1-models/lm.binary'\n",
    "trie = '/home/absin/Downloads/deepspeech-0.5.1-models/trie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file /home/absin/Downloads/deepspeech-0.5.1-models/output_graph.pb\n",
      "Loaded model in 0.0963s.\n"
     ]
    }
   ],
   "source": [
    "print('Loading model from file {}'.format(model), file=sys.stderr)\n",
    "model_load_start = timer()\n",
    "ds = Model(model, N_FEATURES, N_CONTEXT, alphabet, BEAM_WIDTH)\n",
    "model_load_end = timer() - model_load_start\n",
    "print('Loaded model in {:.3}s.'.format(model_load_end), file=sys.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading language model from files /home/absin/Downloads/deepspeech-0.5.1-models/lm.binary /home/absin/Downloads/deepspeech-0.5.1-models/trie\n",
      "Loaded language model in 0.159s.\n"
     ]
    }
   ],
   "source": [
    "print('Loading language model from files {} {}'.format(lm, trie), file=sys.stderr)\n",
    "lm_load_start = timer()\n",
    "ds.enableDecoderWithLM(alphabet, lm, trie, LM_ALPHA, LM_BETA)\n",
    "lm_load_end = timer() - lm_load_start\n",
    "print('Loaded language model in {:.3}s.'.format(lm_load_end), file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__del__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_impl', 'enableDecoderWithLM', 'feedAudioContent', 'finishStream', 'finishStreamWithMetadata', 'intermediateDecode', 'setupStream', 'stt', 'sttWithMetadata']\n"
     ]
    }
   ],
   "source": [
    "print(dir(ds))\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "fs, frames = wavfile.read('/home/absin/Downloads/RE16255e9fec360777c31418c2853372dc_1.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1518720"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 7, 4, ..., 3, 4, 5], dtype=int16)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames[0:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 0.25:0.0016019344329833984\n",
      "Recognized: \n",
      "Done 0.5:0.0038461685180664062\n",
      "Recognized: \n",
      "Done 0.75:0.23262929916381836\n",
      "Recognized: \n",
      "Done 1.0:0.4796748161315918\n",
      "Recognized: \n",
      "Done 1.25:0.7293710708618164\n",
      "Recognized: \n"
     ]
    }
   ],
   "source": [
    "stream_context = ds.setupStream()\n",
    "start = 0\n",
    "start_time = time.time()\n",
    "while(start<frames.shape[0]):\n",
    "    ds.feedAudioContent(stream_context, np.frombuffer(frames[start:start+4000], np.int16))\n",
    "    start += 4000\n",
    "    print('Done '+str(start/16000)+\":\"+str(time.time()-start_time))\n",
    "    \n",
    "    print(\"Recognized: %s\" % ds.intermediateDecode(stream_context))\n",
    "text = ds.finishStream(stream_context)\n",
    "print(\"Recognized: %s\" % text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
